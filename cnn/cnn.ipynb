{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ed4e1a",
   "metadata": {},
   "source": [
    "# Icon Semantic Classification\n",
    "\n",
    "This notebook is heavily based on TensorFlow guides to [Image classification](https://www.tensorflow.org/tutorials/images/classification) and [Transfer learning and fine-tuning](https://www.tensorflow.org/tutorials/images/transfer_learning) which are published under Apache License 2.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4970de52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4e4692",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (96, 96)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "INITIAL_EPOCHS = 20\n",
    "FINE_TUNE_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c623c4ae",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "load the dataset ($D_\\text{mobile}$ or $D_\\text{all}$) from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5675f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"<path_to_dataset>\")\n",
    "\n",
    "ds_train = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_path / \"training\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    color_mode=\"rgb\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    ")\n",
    "\n",
    "ds_validation = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_path / \"validation\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    color_mode=\"rgb\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    ")\n",
    "\n",
    "class_names = ds_train.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# performance tuning\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "ds_train = ds_train.prefetch(buffer_size=AUTOTUNE)\n",
    "ds_validation = ds_validation.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e284be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in ds_train.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i].numpy().argmax()])\n",
    "        plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9153f9",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "rescale images from $[0, 255]$ to $[-1, 1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39cffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = tf.keras.layers.Rescaling(1.0 / 127.5, offset=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52da7f09",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "apply random contrast, translation and zoom to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8740a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomContrast(0.1),\n",
    "        tf.keras.layers.RandomTranslation(0.1, 0.1),\n",
    "        tf.keras.layers.RandomZoom((-0.05, 0)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25796f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, _ in ds_train.take(1):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    first_image = image[0]\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        augmented_image = augmentation(tf.expand_dims(first_image, 0), training=True)\n",
    "        plt.imshow(augmented_image[0] / 255)\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265b2d2a",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f62b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenetv2 = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(IMG_SHAPE), include_top=False, weights=\"imagenet\"\n",
    ")\n",
    "\n",
    "# freeze weights\n",
    "mobilenetv2.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8ae6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
    "x = augmentation(inputs)\n",
    "x = preprocessing(x)\n",
    "x = mobilenetv2(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(num_classes)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134d0adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternativly the baseline model can be used here.\n",
    "# if the baseline model is used the fine tuning step can be skipped.\n",
    "# baseline_cnn = tf.keras.models.Sequential(\n",
    "#     [\n",
    "#         tf.keras.Input(shape=IMG_SHAPE),\n",
    "#         data_augmentation,\n",
    "#         tf.keras.layers.Rescaling(1.0 / 127.5, offset=-1),\n",
    "#         tf.keras.layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"),\n",
    "#         tf.keras.layers.MaxPooling2D(),\n",
    "#         tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "#         tf.keras.layers.MaxPooling2D(),\n",
    "#         tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "#         tf.keras.layers.MaxPooling2D(),\n",
    "#         tf.keras.layers.Dropout(0.2),\n",
    "#         tf.keras.layers.Flatten(),\n",
    "#         tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "#         tf.keras.layers.Dense(num_classes),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af6550f",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9060e95f",
   "metadata": {},
   "source": [
    "### Pre Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a29a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c577cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91209221",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(ds_train, epochs=INITIAL_EPOCHS, validation_data=ds_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d305667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label=\"Training Accuracy\")\n",
    "plt.plot(val_acc, label=\"Validation Accuracy\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim([min(plt.ylim()), 1])\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label=\"Training Loss\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.ylabel(\"Cross Entropy\")\n",
    "plt.ylim([0, 1.0])\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e833795a",
   "metadata": {},
   "source": [
    "### Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b8c10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze weights\n",
    "mobilenetv2.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate / 10),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc3eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb9b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epochs = INITIAL_EPOCHS + FINE_TUNE_EPOCHS\n",
    "\n",
    "history_fine = model.fit(\n",
    "    ds_train,\n",
    "    epochs=total_epochs,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    validation_data=ds_validation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf3f39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc += history_fine.history[\"accuracy\"]\n",
    "val_acc += history_fine.history[\"val_accuracy\"]\n",
    "\n",
    "loss += history_fine.history[\"loss\"]\n",
    "val_loss += history_fine.history[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da8997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label=\"Training Accuracy\")\n",
    "plt.plot(val_acc, label=\"Validation Accuracy\")\n",
    "plt.ylim([0.8, 1])\n",
    "plt.plot(\n",
    "    [INITIAL_EPOCHS - 1, INITIAL_EPOCHS - 1], plt.ylim(), label=\"Start Fine Tuning\"\n",
    ")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label=\"Training Loss\")\n",
    "plt.plot(val_loss, label=\"Validation Loss\")\n",
    "plt.ylim([0, 1.0])\n",
    "plt.plot(\n",
    "    [INITIAL_EPOCHS - 1, INITIAL_EPOCHS - 1], plt.ylim(), label=\"Start Fine Tuning\"\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1a244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b11bae",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "evaluate the models accuracy, precision, recall, f1-score and confusion matrix (e.g. on $D_\\text{web}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e25d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_test = tf.keras.utils.image_dataset_from_directory(\n",
    "#     Path(\"<path_to_test_set>\"),\n",
    "#     shuffle=True,\n",
    "#     seed=42,\n",
    "#     color_mode=\"rgb\",\n",
    "#     label_mode=\"categorical\",\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     image_size=IMG_SIZE,\n",
    "# )\n",
    "ds_test = ds_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7016f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(ds_test)\n",
    "\n",
    "print(\"Loss: {:.2f}\".format(test_loss))\n",
    "print(\"Accuracy: {:.2f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797bd587",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([], dtype=\"float32\")\n",
    "y_true = np.array([], dtype=\"float32\")\n",
    "\n",
    "for images, labels in ds_test:\n",
    "    pred = tf.nn.softmax(model.predict(images)).numpy().argmax(axis=1)\n",
    "    actual = labels.numpy().argmax(axis=1)\n",
    "    y_pred = np.concatenate([y_pred, pred])\n",
    "    y_true = np.concatenate([y_true, actual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0768343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(\n",
    "    y_true, y_pred, target_names=class_names, output_dict=True\n",
    ")\n",
    "with open(\"./classification_report.json\", \"w\") as f:\n",
    "    f.write(json.dumps(report, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d6402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = tf.math.confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(\n",
    "    confusion_matrix,\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    "    annot=True,\n",
    "    fmt=\"g\",\n",
    ")\n",
    "plt.xlabel(\"Prediction\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.savefig(\"confusion_matrix.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0beeda",
   "metadata": {},
   "source": [
    "## Export model for TensorFlow.js\n",
    "\n",
    "To load the model in TensorFlow.js we have to remove the preprocessing and data augmentation layers as they are not supported in TensorFlow.js."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941fa70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs_model = tf.keras.models.Sequential(\n",
    "    [tf.keras.Input(shape=IMG_SHAPE), *model.layers[3:]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ca4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfc9e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if output is still the same\n",
    "test_image = tf.random.uniform((1, *IMG_SHAPE))\n",
    "rescaled_test_image = preprocessing(test_image)\n",
    "print(tf.equal(model(test_image),  tfjs_model(rescaled_test_image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0a4ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs_model.save(\"./tfjs_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9d3f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
